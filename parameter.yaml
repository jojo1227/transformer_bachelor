data:
  max_seq_length: 150
  num_classes: 41
  vocab_size: 31
model:
  dropout_rate: 0.1
  embedding_dim: 32
  num_encoder_layers: 3
  num_heads: 4
training:
  batch_size: 64
  learning_rate: 0.001
  num_epochs: 100
